{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Msingi-AI/Sauti-Ya-Kenya/blob/main/colab/train_tts_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauti Ya Kenya - TTS Training\n",
    "\n",
    "This notebook sets up the training environment for our Swahili TTS model using TPU/GPU acceleration.\n",
    "\n",
    "## Dataset Upload Instructions\n",
    "You'll need to upload your Common Voice dataset files in this order:\n",
    "1. `validated_sentences.tsv` ✅\n",
    "2. `clip_durations.tsv` ✅\n",
    "3. Upload individual audio clips in batches:\n",
    "   - Create a folder named `clips` in your Google Drive\n",
    "   - Upload your audio files there\n",
    "   - We'll mount the Drive and copy them over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available hardware\n",
    "import torch\n",
    "try:\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    print(\"TPU available!\")\n",
    "    DEVICE = xm.xla_device()\n",
    "    USE_TPU = True\n",
    "except ImportError:\n",
    "    print(\"TPU not found, checking for GPU...\")\n",
    "    USE_TPU = False\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "        DEVICE = torch.device('cuda')\n",
    "    else:\n",
    "        print(\"No GPU found, using CPU\")\n",
    "        DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directories\n",
    "!mkdir -p cv-corpus-21.0-delta-2025-03-14/sw/clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and install dependencies\n",
    "!git clone https://github.com/Msingi-AI/Sauti-Ya-Kenya.git\n",
    "%cd Sauti-Ya-Kenya\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install TPU support if available\n",
    "if USE_TPU:\n",
    "    !pip install cloud-tpu-client==0.10 torch_xla[tpu]>=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload TSV files\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"Please upload validated_sentences.tsv and clip_durations.tsv\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move files to correct location\n",
    "dataset_path = \"cv-corpus-21.0-delta-2025-03-14/sw\"\n",
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    os.rename(filename, os.path.join(dataset_path, filename))\n",
    "    print(f\"Moved {filename} to {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy audio clips from Google Drive\n",
    "import shutil\n",
    "\n",
    "drive_clips_path = \"/content/drive/MyDrive/common_voice_clips\"\n",
    "local_clips_path = os.path.join(dataset_path, \"clips\")\n",
    "\n",
    "print(\"Copying audio clips from Google Drive...\")\n",
    "print(f\"Source: {drive_clips_path}\")\n",
    "print(f\"Destination: {local_clips_path}\")\n",
    "\n",
    "# Create destination directory\n",
    "os.makedirs(local_clips_path, exist_ok=True)\n",
    "\n",
    "# Copy files in batches to avoid memory issues\n",
    "import glob\n",
    "batch_size = 100\n",
    "audio_files = glob.glob(os.path.join(drive_clips_path, \"*.mp3\"))\n",
    "\n",
    "for i in range(0, len(audio_files), batch_size):\n",
    "    batch = audio_files[i:i + batch_size]\n",
    "    for audio_file in batch:\n",
    "        filename = os.path.basename(audio_file)\n",
    "        shutil.copy2(audio_file, os.path.join(local_clips_path, filename))\n",
    "    print(f\"Copied {min(i + batch_size, len(audio_files))}/{len(audio_files)} files\")\n",
    "\n",
    "print(\"\\nAudio files copied successfully!\")\n",
    "print(f\"Total files: {len(os.listdir(local_clips_path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process dataset\n",
    "!python src/prepare_local_dataset.py \\\n",
    "    --dataset_path \"cv-corpus-21.0-delta-2025-03-14/sw\" \\\n",
    "    --output_dir \"processed_data\" \\\n",
    "    --clips_path \"clips\" \\\n",
    "    --sentences_file \"validated_sentences.tsv\" \\\n",
    "    --durations_file \"clip_durations.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data augmentation\n",
    "!python src/augment_data.py \\\n",
    "    --data_dir \"processed_data\" \\\n",
    "    --output_dir \"augmented_data\" \\\n",
    "    --num_augmentations 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training configuration\n",
    "import json\n",
    "\n",
    "# Optimize batch size based on hardware\n",
    "if USE_TPU:\n",
    "    batch_size = 128  # TPUs handle larger batches efficiently\n",
    "elif torch.cuda.is_available():\n",
    "    batch_size = 32   # Standard GPU batch size\n",
    "else:\n",
    "    batch_size = 8    # Smaller batch for CPU\n",
    "\n",
    "config = {\n",
    "    \"train_data_dir\": \"augmented_data\",\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 100,\n",
    "    \"save_every\": 10,\n",
    "    \"device\": str(DEVICE),\n",
    "    \"max_len\": 10000,  # Based on our Swahili optimization\n",
    "    \"checkpoint_dir\": \"checkpoints\",\n",
    "    \"use_tpu\": USE_TPU,\n",
    "    \"gradient_accumulation_steps\": 1 if USE_TPU else 2  # Help with memory on GPU\n",
    "}\n",
    "\n",
    "with open('config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(f\"Using device: {config['device']}\")\n",
    "print(f\"Batch size: {config['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "!python src/train.py --config config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "!python src/evaluation.py \\\n",
    "    --model_path \"checkpoints/best.pt\" \\\n",
    "    --test_data \"augmented_data/test\" \\\n",
    "    --output_dir \"evaluation_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to Google Drive\n",
    "drive_path = \"/content/drive/MyDrive/Sauti-Ya-Kenya/models\"\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "# Copy best model\n",
    "shutil.copy(\"checkpoints/best.pt\", f\"{drive_path}/best.pt\")\n",
    "\n",
    "# Save evaluation results\n",
    "shutil.copytree(\"evaluation_results\", f\"{drive_path}/evaluation_results\", dirs_exist_ok=True)\n",
    "\n",
    "print(\"Model and evaluation results saved to Google Drive\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "train_tts_new.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
