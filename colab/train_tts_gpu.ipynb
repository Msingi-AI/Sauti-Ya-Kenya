{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Msingi-AI/Sauti-Ya-Kenya/blob/main/colab/train_tts_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauti Ya Kenya - TTS Training (GPU Version)\n",
    "\n",
    "This notebook trains the Swahili TTS model using GPU acceleration.\n",
    "\n",
    "## Setup Steps:\n",
    "1. Mount Google Drive\n",
    "2. Install dependencies\n",
    "3. Upload dataset files\n",
    "4. Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"No GPU found! Go to Runtime > Change runtime type and select GPU\")\n",
    "\n",
    "print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and install dependencies\n",
    "!git clone https://github.com/Msingi-AI/Sauti-Ya-Kenya.git\n",
    "%cd Sauti-Ya-Kenya\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset directory\n",
    "import os\n",
    "dataset_dir = \"cv-corpus-21.0-delta-2025-03-14/sw\"\n",
    "clips_dir = os.path.join(dataset_dir, \"clips\")\n",
    "os.makedirs(clips_dir, exist_ok=True)\n",
    "\n",
    "# Upload dataset files\n",
    "from google.colab import files\n",
    "print(\"Please upload the following files in order:\")\n",
    "print(\"1. validated_sentences.tsv\")\n",
    "print(\"2. clip_durations.tsv\")\n",
    "print(\"3. All clips_part_*.zip files\")\n",
    "\n",
    "# Handle TSV files first\n",
    "print(\"\\nUploading TSV files...\")\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.tsv'):\n",
    "        dest_path = os.path.join(dataset_dir, filename)\n",
    "        with open(dest_path, 'wb') as f:\n",
    "            f.write(uploaded[filename])\n",
    "        print(f\"Saved {filename}\")\n",
    "\n",
    "# Now handle zip files\n",
    "print(\"\\nUploading and extracting clip files...\")\n",
    "while True:\n",
    "    try:\n",
    "        uploaded = files.upload()\n",
    "        if not uploaded:\n",
    "            break\n",
    "            \n",
    "        for filename in uploaded.keys():\n",
    "            if filename.startswith('clips_part_') and filename.endswith('.zip'):\n",
    "                print(f\"Extracting {filename}...\")\n",
    "                import zipfile\n",
    "                with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(dataset_dir)\n",
    "                os.remove(filename)  # Clean up zip file\n",
    "                print(f\"Extracted {filename}\")\n",
    "    except Exception as e:\n",
    "        if \"No file selected\" in str(e):\n",
    "            break\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "print(\"\\nDataset preparation complete!\")\n",
    "print(f\"Number of audio files: {len(os.listdir(clips_dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process dataset with GPU acceleration\n",
    "!CUDA_VISIBLE_DEVICES=0 python src/prepare_local_dataset.py \\\n",
    "    --dataset_path \"cv-corpus-21.0-delta-2025-03-14/sw\" \\\n",
    "    --output_dir \"processed_data\" \\\n",
    "    --clips_path \"clips\" \\\n",
    "    --sentences_file \"validated_sentences.tsv\" \\\n",
    "    --durations_file \"clip_durations.tsv\" \\\n",
    "    --use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data augmentation with GPU\n",
    "!CUDA_VISIBLE_DEVICES=0 python src/augment_data.py \\\n",
    "    --data_dir \"processed_data\" \\\n",
    "    --output_dir \"augmented_data\" \\\n",
    "    --num_augmentations 3 \\\n",
    "    --use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPU-optimized training configuration\n",
    "import json\n",
    "\n",
    "config = {\n",
    "    \"train_data_dir\": \"augmented_data\",\n",
    "    \"batch_size\": 32,           # Optimized for GPU\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_epochs\": 100,\n",
    "    \"save_every\": 10,\n",
    "    \"device\": \"cuda\",\n",
    "    \"max_len\": 10000,          # Based on our Swahili optimization\n",
    "    \"checkpoint_dir\": \"checkpoints\",\n",
    "    \"gradient_accumulation_steps\": 2,  # Help with GPU memory\n",
    "    \"mixed_precision\": True,    # Use FP16 for faster training\n",
    "    \"num_workers\": 4,          # Parallel data loading\n",
    "    \"pin_memory\": True         # Faster GPU data transfer\n",
    "}\n",
    "\n",
    "with open('config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for k, v in config.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start GPU training\n",
    "!CUDA_VISIBLE_DEVICES=0 python src/train.py --config config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "!CUDA_VISIBLE_DEVICES=0 python src/evaluation.py \\\n",
    "    --model_path \"checkpoints/best.pt\" \\\n",
    "    --test_data \"augmented_data/test\" \\\n",
    "    --output_dir \"evaluation_results\" \\\n",
    "    --use_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to Google Drive\n",
    "drive_path = \"/content/drive/MyDrive/Sauti-Ya-Kenya/models\"\n",
    "os.makedirs(drive_path, exist_ok=True)\n",
    "\n",
    "# Copy best model and results\n",
    "import shutil\n",
    "shutil.copy(\"checkpoints/best.pt\", f\"{drive_path}/best.pt\")\n",
    "shutil.copytree(\"evaluation_results\", f\"{drive_path}/evaluation_results\", dirs_exist_ok=True)\n",
    "\n",
    "print(\"Model and evaluation results saved to Google Drive\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "train_tts_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
