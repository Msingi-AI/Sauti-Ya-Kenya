{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üéôÔ∏è Sauti Ya Kenya - TTS Model Training\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Msingi-AI/Sauti-Ya-Kenya/blob/main/notebooks/train_tts_model.ipynb)\n",
    "\n",
    "This notebook provides an optimized training environment for the Kenyan Swahili Text-to-Speech model. Features:\n",
    "- üöÄ GPU-accelerated training\n",
    "- üíæ Efficient memory management\n",
    "- üìä Progress tracking\n",
    "- üîÑ Automatic checkpoint saving\n",
    "\n",
    "## Setup Instructions\n",
    "1. Upload `data.zip` to your Google Drive\n",
    "2. Connect to a GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "3. Run all cells in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Verify GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e9:.1f}GB\")\n",
    "    print(f\"Memory cached: {torch.cuda.memory_reserved() / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "# Clone repository and install dependencies\n",
    "!git clone https://github.com/Msingi-AI/Sauti-Ya-Kenya.git\n",
    "%cd Sauti-Ya-Kenya\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Create symlink to checkpoints directory in Drive\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "drive_path = Path('/content/drive/MyDrive/Sauti-Ya-Kenya')\n",
    "checkpoints_dir = drive_path / 'checkpoints'\n",
    "checkpoints_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not os.path.exists('checkpoints'):\n",
    "    !ln -s {checkpoints_dir} checkpoints\n",
    "\n",
    "# Extract data\n",
    "data_zip = drive_path / 'data.zip'\n",
    "if data_zip.exists():\n",
    "    !unzip -q {data_zip}\n",
    "    print(\"‚úÖ Data extracted successfully\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Please upload data.zip to /content/drive/MyDrive/Sauti-Ya-Kenya/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_data"
   },
   "outputs": [],
   "source": [
    "# Verify data structure\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def verify_data():\n",
    "    # Check metadata files\n",
    "    train_meta = pd.read_csv('processed_data/train_metadata.csv')\n",
    "    val_meta = pd.read_csv('processed_data/val_metadata.csv')\n",
    "    print(f\"Train samples: {len(train_meta)}\")\n",
    "    print(f\"Val samples: {len(val_meta)}\")\n",
    "    \n",
    "    # Verify feature files for first training sample\n",
    "    sample_id = train_meta.iloc[0]['id']\n",
    "    features = ['text_tokens', 'mel', 'duration']\n",
    "    \n",
    "    for feature in features:\n",
    "        path = f'processed_data/train/{feature}/{sample_id}.npy'\n",
    "        data = np.load(path)\n",
    "        print(f\"\\n{feature} shape: {data.shape}\")\n",
    "\n",
    "verify_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "optimize_memory"
   },
   "outputs": [],
   "source": [
    "# Optimize memory settings\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "def optimize_memory():\n",
    "    # Empty CUDA cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Run garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    # Set memory allocator settings\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.set_per_process_memory_fraction(0.9)\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "optimize_memory()\n",
    "\n",
    "# Print memory status\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1e9:.1f}GB\")\n",
    "    print(f\"Memory cached: {torch.cuda.memory_reserved() / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train"
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "!python -m src.train \\\n",
    "    --batch_size 8 \\\n",
    "    --grad_accum 4 \\\n",
    "    --epochs 100 \\\n",
    "    --save_every 10 \\\n",
    "    --checkpoint_dir checkpoints"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Sauti Ya Kenya - TTS Training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
