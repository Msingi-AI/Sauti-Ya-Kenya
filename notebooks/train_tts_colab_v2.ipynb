{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sauti ya Kenya - TTS Training\n",
    "\n",
    "This notebook trains the Kenyan Swahili TTS model using FastSpeech 2 architecture with memory optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory structure\n",
    "!mkdir -p /content/drive/MyDrive/Sauti-Ya-Kenya/data/{processed,tokenizer}\n",
    "!mkdir -p /content/drive/MyDrive/Sauti-Ya-Kenya/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone repository and install dependencies\n",
    "!git clone https://github.com/Msingi-AI/Sauti-Ya-Kenya.git\n",
    "%cd Sauti-Ya-Kenya\n",
    "!pip install -r requirements.txt\n",
    "!pip install torch==2.2.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload data to Drive first!\n",
    "print(\"Before running this cell:\")\n",
    "print(\"1. Upload your processed data to: /content/drive/MyDrive/Sauti-Ya-Kenya/data/processed/\")\n",
    "print(\"2. Upload your tokenizer files to: /content/drive/MyDrive/Sauti-Ya-Kenya/data/tokenizer/\")\n",
    "\n",
    "# Check if data exists\n",
    "!ls -la /content/drive/MyDrive/Sauti-Ya-Kenya/data/processed/\n",
    "!ls -la /content/drive/MyDrive/Sauti-Ya-Kenya/data/tokenizer/\n",
    "\n",
    "# Create local directories\n",
    "!mkdir -p data/{processed,tokenizer}\n",
    "\n",
    "# Copy data only if source exists\n",
    "if [ -d \"/content/drive/MyDrive/Sauti-Ya-Kenya/data/processed\" ]; then\n",
    "    !cp -r \"/content/drive/MyDrive/Sauti-Ya-Kenya/data/processed\"/* data/processed/\n",
    "fi\n",
    "\n",
    "if [ -d \"/content/drive/MyDrive/Sauti-Ya-Kenya/data/tokenizer\" ]; then\n",
    "    !cp -r \"/content/drive/MyDrive/Sauti-Ya-Kenya/data/tokenizer\"/* data/tokenizer/\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# First, zip your local data\n",
    "!cd /content && zip -r drive/MyDrive/Sauti-Ya-Kenya/data.zip Sauti-Ya-Kenya/data/\n",
    "print(\"Data has been zipped to drive/MyDrive/Sauti-Ya-Kenya/data.zip\")\n",
    "print(\"You can now download this file and upload it to Drive manually if needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "from preprocessor import SwahiliTokenizer\n",
    "from model import FastSpeech2\n",
    "from dataset import TTSDataset\n",
    "from config import ModelConfig\n",
    "\n",
    "# Memory optimizations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Load config\n",
    "config = ModelConfig()\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = SwahiliTokenizer(vocab_size=8000)\n",
    "tokenizer.load('data/tokenizer/tokenizer.model')\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TTSDataset(\n",
    "    data_dir='data/processed',\n",
    "    metadata_file='data/processed/metadata.csv',\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
