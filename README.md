# üéôÔ∏è Sauti Ya Kenya 

<div align="center">

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
<a href="https://colab.research.google.com/github/Msingi-AI/Sauti-Ya-Kenya/blob/main/notebooks/train_tts_model.ipynb" target="_blank">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

![image](https://github.com/user-attachments/assets/93e891f3-5828-4cee-8f78-016d98fa1ff2)

*Bringing Kenyan Swahili voices to life through AI* üá∞üá™

[Getting Started](#getting-started) ‚Ä¢
[Features](#features) ‚Ä¢
[Documentation](#documentation) ‚Ä¢
[Contributing](#contributing) ‚Ä¢
[Contact](#contact)

</div>

---

## üåü Overview

Sauti Ya Kenya is a state-of-the-art Text-to-Speech (TTS) system specifically designed for Kenyan Swahili. Our model handles:
- üó£Ô∏è Natural Kenyan Swahili pronunciation
- üîÑ Code-switching between Swahili and English
- üì¢ Multiple speaker voices
- üéØ Local expressions and idioms

## ‚ú® Features

- **High-Quality Speech** - FastSpeech 2 architecture for fast, high-fidelity voice synthesis
- **Code-Switching** - Seamlessly handles mixed Swahili-English text
- **Local Optimization** - Tuned specifically for Kenyan Swahili phonetics
- **Easy Integration** - Simple API for quick integration into your projects
- **Memory Efficient** - Optimized for training on Google Colab

## üöÄ Getting Started

### Prerequisites

```bash
python 3.8+
pytorch 2.0+
torchaudio
numpy
pandas
```

### Installation

1. Clone the repository:
```bash
git clone https://github.com/Msingi-AI/Sauti-Ya-Kenya.git
cd Sauti-Ya-Kenya
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Download the pre-trained models:
- Download the FastSpeech2 model from [releases](https://github.com/Msingi-AI/Sauti-Ya-Kenya/releases)
- Place it in the `models` directory

### Quick Start

```python
import torch
from src.inference import load_model, synthesize
from src.preprocessor import TextPreprocessor, SwahiliTokenizer
from src.vocoder import load_hifigan

# Load models
model = load_model("models/tts_model.pt")
tokenizer = SwahiliTokenizer()
tokenizer.load("models/tokenizer.model")
preprocessor = TextPreprocessor(tokenizer)
vocoder = load_hifigan()

# Synthesize speech
text = "Karibu kwenye mfano wa matini-hadi-usemi."
audio = synthesize(text, model, preprocessor, vocoder)

# Save audio
import torchaudio
torchaudio.save("output.wav", audio.unsqueeze(0), 22050)
```

### Examples

Check out `examples/tts_demo.py` for a complete example of how to use the model.

To run the demo:
```bash
python examples/tts_demo.py
```

## Contributing Voice Data üó£Ô∏è

We welcome voice contributions from Kenyan Swahili speakers! Your voice will help create a more diverse and representative model.

### Speaker Requirements

- Native or fluent Kenyan Swahili speaker
- Clear pronunciation
- Comfortable with both Swahili and English (for code-switching)
- Consistent speaking style

### Recording Guidelines

1. **Environment**:
   - Find a quiet room with minimal echo
   - Avoid background noise and interruptions
   - Use a good quality microphone if possible
   - Record during quiet hours to minimize ambient noise

2. **Recording Setup**:
   - Run the data collection tool:
     ```bash
     python -m src.data_collection
     ```
   - Fill in your speaker details in the GUI:
     - Name (or pseudonym)
     - Age range
     - Gender
     - Primary dialect/region
     - Years speaking Kenyan Swahili
   - Maintain consistent distance from microphone (about 6-8 inches)
   - Speak clearly and naturally

3. **Recording Process**:
   - Each session will present text prompts to read
   - Take time to read and understand each prompt before recording
   - Click "Record" to start recording
   - Read the text naturally at your normal speaking pace
   - Feel free to use your natural code-switching style
   - Click "Stop" when finished
   - Review the recording and re-record if needed
   - Save the recording when satisfied

4. **Quality Check**:
   - Recordings should be clear and understandable
   - No background noise or interruptions
   - Natural speaking rhythm and intonation
   - Consistent volume level
   - Authentic Kenyan Swahili pronunciation

### Text Guidelines

When recording, you'll encounter different types of text:
1. Pure Swahili sentences
2. Mixed Swahili-English sentences (code-switching)
3. Common Kenyan expressions
4. Numbers and dates
5. Questions and exclamations

Read each type naturally, as you would in everyday conversation.

## Training the Model üß†

### Training on Google Colab (Recommended)

<a href="https://colab.research.google.com/github/Msingi-AI/Sauti-Ya-Kenya/blob/main/notebooks/train_tts_model.ipynb" target="_blank">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

We recommend using Google Colab for training as it provides:
- Free GPU access
- Optimized memory settings
- Easy environment setup
- Automatic checkpoint saving to Google Drive

To train the model:
1. Click the "Open in Colab" button above (opens in new tab)
2. Connect to a GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU)
3. Run the setup cells to mount Drive and install dependencies
4. Upload your preprocessed data or use our sample dataset
5. Start training with optimized settings:
   - Batch size: 8
   - Gradient accumulation: 4 steps
   - Automatic memory cleanup
   - Progress tracking
   - Checkpoint management

### Local Training (Advanced)

For local training (only recommended if you have a powerful GPU), use:
```bash
python -m src.train --batch_size 8 --grad_accum 4
```

Note: Local training requires:
- NVIDIA GPU with 12GB+ VRAM
- CUDA toolkit
- All dependencies installed
- Preprocessed data in the correct format

## Training Parameters

The training script accepts the following parameters:
```bash
python -m src.train \
    --batch_size 8 \          # Batch size for training
    --grad_accum 4 \          # Number of gradient accumulation steps
    --epochs 100 \            # Total number of training epochs
    --save_every 10 \         # Save checkpoint every N epochs
    --checkpoint_dir checkpoints  # Directory to save checkpoints
    --resume path/to/checkpoint.pt  # Optional: Resume from checkpoint
```

### Memory Optimization
The training is optimized for efficient GPU memory usage with:
- Reduced batch size (8)
- Gradient accumulation (4 steps)
- Automatic CUDA cache cleanup
- Memory monitoring
- OneCycleLR scheduler with cosine annealing

## Using the API üîå

### Quick Start

```python
from src.api import TTSEngine

# Initialize the TTS engine
engine = TTSEngine(model_path='checkpoints/best.pt')

# Generate speech
text = "Habari yako! How are you today?"
audio = engine.synthesize(text)

# Save to file
engine.save_audio(audio, 'output.wav')
```

### Advanced Usage

```python
# Custom configuration
engine = TTSEngine(
    model_path='checkpoints/best.pt',
    device='cuda',  # Use GPU if available
    sampling_rate=22050,
    language_mode='auto'  # Auto-detect language for code-switching
)

# Batch processing
texts = [
    "Niko na meeting leo jioni.",
    "Tutakutana kesho at the mall.",
    "Bei ni fifty shillings tu."
]

audios = engine.synthesize_batch(texts)

# Save multiple files
for i, audio in enumerate(audios):
    engine.save_audio(audio, f'output_{i}.wav')

# Stream audio directly
import sounddevice as sd

audio = engine.synthesize("Karibu tena!")
sd.play(audio, engine.sampling_rate)
sd.wait()  # Wait until audio finishes playing
```

### API Configuration

The TTS engine supports various configuration options:

```python
engine = TTSEngine(
    model_path='path/to/model',
    device='cuda',           # 'cuda' or 'cpu'
    sampling_rate=22050,     # Output audio sampling rate
    language_mode='auto',    # 'auto', 'swahili', 'mixed'
    speed_factor=1.0,       # Adjust speaking speed
    energy_factor=1.0,      # Adjust volume/energy
    pitch_factor=1.0,       # Adjust pitch
    use_cache=True          # Cache generated mel spectrograms
)
```

### Error Handling

```python
try:
    audio = engine.synthesize("Your text here")
except ValueError as e:
    print(f"Invalid input: {e}")
except RuntimeError as e:
    print(f"Generation failed: {e}")
```

For more examples and detailed API documentation, see our [API Reference](docs/api.md).

## Project Structure üìÅ

```
Sauti-Ya-Kenya/
‚îú‚îÄ‚îÄ data/                     # Raw audio recordings and metadata
‚îú‚îÄ‚îÄ processed_data/           # Preprocessed training data
‚îú‚îÄ‚îÄ notebooks/               # Jupyter notebooks
‚îÇ   ‚îî‚îÄ‚îÄ train_tts_model.ipynb  # Optimized Colab training notebook
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_collection.py   # GUI tool for recording
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_data.py   # Data preprocessing pipeline
‚îÇ   ‚îú‚îÄ‚îÄ model.py            # FastSpeech 2 model implementation
‚îÇ   ‚îú‚îÄ‚îÄ train.py            # Training script with memory optimization
‚îÇ   ‚îî‚îÄ‚îÄ api.py              # Inference API
‚îú‚îÄ‚îÄ checkpoints/            # Model checkpoints
‚îú‚îÄ‚îÄ CONTRIBUTING.md         # Contribution guidelines
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md      # Community code of conduct
‚îî‚îÄ‚îÄ requirements.txt        # Project dependencies
```

## Model Architecture üèóÔ∏è

The TTS system uses FastSpeech 2 architecture with:
- Multi-head self-attention for text encoding
- Duration predictor for length regulation
- Mel-spectrogram decoder
- Parallel generation for fast inference

### Language-Specific Features

The model includes special handling for:
- Code-switching detection and processing
- Local expression preservation
- Proper nouns and place names
- Kenyan English accent patterns
- Common abbreviations and numerals

## üìû Contact & Support

- **Email**: [information.msingiai@gmail.com](mailto:information.msingiai@gmail.com)
- **Issues**: [GitHub Issues](https://github.com/Msingi-AI/Sauti-Ya-Kenya/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Msingi-AI/Sauti-Ya-Kenya/discussions)

## ü§ù Contributing

We welcome contributions! See our [Contributing Guidelines](CONTRIBUTING.md) for details on:
- Setting up your development environment
- Recording voice data
- Submitting pull requests
- Code style guidelines

Please read our [Code of Conduct](CODE_OF_CONDUCT.md) before contributing.

## üìú License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

Made with ‚ù§Ô∏è by [Msingi AI](https://github.com/Msingi-AI)

</div>
