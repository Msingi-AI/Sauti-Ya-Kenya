{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq7v_7m0hgSd",
        "outputId": "88a407a4-bef5-494c-8957-307a96d88146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix NumPy version issue first\n",
        "!pip uninstall -y numpy\n",
        "!pip install 'numpy<2.0.0'\n",
        "\n",
        "# Clone repository and install dependencies\n",
        "!git clone https://github.com/Msingi-AI/Sauti-Ya-Kenya.git\n",
        "%cd Sauti-Ya-Kenya\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhCPEQJ3h2Gj",
        "outputId": "bc01957e-28c6-4d1c-f966-43c790fb04ae"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy<2.0.0\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "Successfully installed numpy-1.26.4\n",
            "Cloning into 'Sauti-Ya-Kenya'...\n",
            "remote: Enumerating objects: 1529, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 1529 (delta 0), reused 2 (delta 0), pack-reused 1523 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1529/1529), 133.08 MiB | 31.82 MiB/s, done.\n",
            "Resolving deltas: 100% (664/664), done.\n",
            "/content/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya/Sauti-Ya-Kenya\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: librosa>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: soundfile>=0.10.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.13.1)\n",
            "Requirement already satisfied: datasets>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: transformers>=4.25.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.50.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: sentencepiece>=0.1.97 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: jiwer>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (3.10.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.21.1)\n",
            "Requirement already satisfied: nltk>=3.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.9.0->-r requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.3->-r requirements.txt (line 5)) (1.17.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.0->-r requirements.txt (line 7)) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.0->-r requirements.txt (line 7)) (0.5.3)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer>=3.0.0->-r requirements.txt (line 10)) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer>=3.0.0->-r requirements.txt (line 10)) (3.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->-r requirements.txt (line 11)) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 12)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 12)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 12)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 12)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r requirements.txt (line 12)) (3.2.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.3->-r requirements.txt (line 5)) (2.22)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (1.18.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.9.0->-r requirements.txt (line 4)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.9.0->-r requirements.txt (line 4)) (4.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->-r requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.10.0->-r requirements.txt (line 6)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.10.0->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.10.0->-r requirements.txt (line 6)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.10.0->-r requirements.txt (line 6)) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa>=0.9.0->-r requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Create data structure\n",
        "!mkdir -p data/processed data/tokenizer\n",
        "\n",
        "# Copy data from Drive\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/Sauti-Ya-Kenya-1\"\n",
        "\n",
        "!cp -r \"/content/drive/MyDrive/Sauti-Ya-Kenya-1/data/processed\" data/\n",
        "!cp -r \"/content/drive/MyDrive/Sauti-Ya-Kenya-1/tokenizer\" data/\n",
        "\n",
        "\n",
        "# Verify files\n",
        "print(\"\\nChecking data structure:\")\n",
        "!ls -R data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2W37pfCtAjD",
        "outputId": "8d127b04-fc0c-423e-cb8d-6d2fb04661dd"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/Sauti-Ya-Kenya-1/tokenizer': No such file or directory\n",
            "\n",
            "Checking data structure:\n",
            "data/:\n",
            "metadata.json  processed  text\ttokenizer\n",
            "\n",
            "data/processed:\n",
            "metadata.csv  Speaker_003  Speaker_007\tSpeaker_011  Speaker_015  Speaker_019\n",
            "Speaker_000   Speaker_004  Speaker_008\tSpeaker_012  Speaker_016  Speaker_020\n",
            "Speaker_001   Speaker_005  Speaker_009\tSpeaker_013  Speaker_017\n",
            "Speaker_002   Speaker_006  Speaker_010\tSpeaker_014  Speaker_018\n",
            "\n",
            "data/processed/Speaker_000:\n",
            "clip_0000_mel.pt  clip_0000_text.txt  clip_0000.wav\n",
            "\n",
            "data/processed/Speaker_001:\n",
            "clip_0001_mel.pt    clip_0001.wav\tclip_0003_text.txt  clip_0005_text.txt\n",
            "clip_0001_text.txt  clip_0002_text.txt\tclip_0004_text.txt\n",
            "\n",
            "data/processed/Speaker_002:\n",
            "clip_0002_mel.pt  clip_0002_text.txt  clip_0002.wav\n",
            "\n",
            "data/processed/Speaker_003:\n",
            "clip_0003_mel.pt  clip_0003_text.txt  clip_0003.wav\n",
            "\n",
            "data/processed/Speaker_004:\n",
            "clip_0004_mel.pt  clip_0004_text.txt  clip_0004.wav\n",
            "\n",
            "data/processed/Speaker_005:\n",
            "clip_0005_mel.pt  clip_0005_text.txt  clip_0005.wav\n",
            "\n",
            "data/processed/Speaker_006:\n",
            "clip_0006_mel.pt  clip_0006_text.txt  clip_0006.wav\n",
            "\n",
            "data/processed/Speaker_007:\n",
            "clip_0007_mel.pt  clip_0007_text.txt  clip_0007.wav\n",
            "\n",
            "data/processed/Speaker_008:\n",
            "clip_0008_mel.pt  clip_0008_text.txt  clip_0008.wav\n",
            "\n",
            "data/processed/Speaker_009:\n",
            "clip_0009_mel.pt  clip_0009_text.txt  clip_0009.wav\n",
            "\n",
            "data/processed/Speaker_010:\n",
            "clip_0010_mel.pt  clip_0010_text.txt  clip_0010.wav\n",
            "\n",
            "data/processed/Speaker_011:\n",
            "clip_0011_mel.pt  clip_0011_text.txt  clip_0011.wav\n",
            "\n",
            "data/processed/Speaker_012:\n",
            "clip_0012_mel.pt  clip_0012_text.txt  clip_0012.wav\n",
            "\n",
            "data/processed/Speaker_013:\n",
            "clip_0013_mel.pt  clip_0013_text.txt  clip_0013.wav\n",
            "\n",
            "data/processed/Speaker_014:\n",
            "clip_0014_mel.pt  clip_0014_text.txt  clip_0014.wav\n",
            "\n",
            "data/processed/Speaker_015:\n",
            "clip_0015_mel.pt  clip_0015_text.txt  clip_0015.wav\n",
            "\n",
            "data/processed/Speaker_016:\n",
            "clip_0016_mel.pt  clip_0016_text.txt  clip_0016.wav\n",
            "\n",
            "data/processed/Speaker_017:\n",
            "clip_0017_mel.pt  clip_0017_text.txt  clip_0017.wav\n",
            "\n",
            "data/processed/Speaker_018:\n",
            "clip_0018_mel.pt  clip_0018_text.txt  clip_0018.wav\n",
            "\n",
            "data/processed/Speaker_019:\n",
            "clip_0019_mel.pt  clip_0019_text.txt  clip_0019.wav\n",
            "\n",
            "data/processed/Speaker_020:\n",
            "clip_0020_mel.pt  clip_0020_text.txt  clip_0020.wav\n",
            "\n",
            "data/text:\n",
            "sample.txt  tokenizer_training_data.txt\n",
            "\n",
            "data/tokenizer:\n",
            "tokenizer.model  tokenizer.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create __init__.py to make src a package\n",
        "!touch src/__init__.py\n",
        "\n",
        "# Add src to Python path\n",
        "import sys\n",
        "sys.path.insert(0, os.path.abspath('src'))\n",
        "\n",
        "# Fix imports in train.py\n",
        "with open('src/train.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Fix relative imports\n",
        "content = content.replace('from .model', 'from model')\n",
        "content = content.replace('from .preprocessor', 'from preprocessor')\n",
        "\n",
        "with open('src/train.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"Fixed imports in train.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "268u1s3Iktkx",
        "outputId": "1f785a70-96ec-41a0-ee09-3045f67285e2"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed imports in train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure GPU\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB\")\n",
        "else:\n",
        "    raise RuntimeError(\"No GPU available!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng8gqULvkx4x",
        "outputId": "155af845-d572-40d8-ccd1-29fe117cc837"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n",
            "GPU Memory: 14.7GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/Sauti-Ya-Kenya-1/checkpoints"
      ],
      "metadata": {
        "id": "RPidRW6TNklR"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python src/train.py \\\n",
        "    --batch_size 4 \\\n",
        "    --grad_accum 4 \\\n",
        "    --checkpoint_dir /content/drive/MyDrive/Sauti-Ya-Kenya-1/checkpoints \\\n",
        "    --data_dir data/processed \\\n",
        "    --metadata_path data/processed/metadata.csv \\\n",
        "    --tokenizer_path data/tokenizer/tokenizer.model \\\n",
        "    --epochs 100 \\\n",
        "    --save_every 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1Liti3ck6kn",
        "outputId": "2e92970b-74a8-485a-85da-1dee6b366f28"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([636, 80])\n",
            "Mel 1: torch.Size([512, 80])\n",
            "Mel 2: torch.Size([788, 80])\n",
            "Mel 3: torch.Size([438, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 788\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "Raw text: '41928559'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([645, 80])\n",
            "Mel 1: torch.Size([639, 80])\n",
            "Mel 2: torch.Size([357, 80])\n",
            "Mel 3: torch.Size([912, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 912\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])duration_target: torch.Size([4, 8])\n",
            "\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "Raw text: '41928561'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([444, 80])\n",
            "Mel 1: torch.Size([642, 80])\n",
            "Mel 2: torch.Size([692, 80])\n",
            "Mel 3: torch.Size([1083, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 11, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 11, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 11, 384])\n",
            "After positional encoding shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "After final norm shape: torch.Size([4, 11, 384])\n",
            "Final mel output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 11, 80])\n",
            "Validation:  17% 1/6 [00:00<00:00,  8.74it/s]\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([593, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 593\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 9, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 9, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 9, 384])\n",
            "After positional encoding shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "After final norm shape: torch.Size([4, 9, 384])\n",
            "Final mel output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 10, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 10, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 10, 384])\n",
            "After positional encoding shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "After final norm shape: torch.Size([4, 10, 384])\n",
            "Final mel output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 6, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 6, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 6, 384])\n",
            "After positional encoding shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "After final norm shape: torch.Size([1, 6, 384])\n",
            "Final mel output shape: torch.Size([1, 6, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 6, 80])\n",
            "Validation: 100% 6/6 [00:00<00:00, 28.69it/s]\n",
            "Validation Loss: 0.0454\n",
            "\n",
            "Epoch 97/100\n",
            "Starting training epoch...\n",
            "Training:   0% 0/6 [00:00<?, ?it/s]\n",
            "Loaded and tokenized text for clip_0001: torch.Size([8])\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "\n",
            "Raw text: '42691259'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 123, 74]\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0002: torch.Size([8])\n",
            "Raw text: '42146600'\n",
            "Token IDs: [142, 37, 21, 142, 148, 148, 2349, 2349]\n",
            "Loaded and processed mel shape for clip_0002: torch.Size([1014, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0012: torch.Size([8])\n",
            "Raw text: '42146486'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 148]\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([1083, 80])\n",
            "Mel 1: torch.Size([1014, 80])\n",
            "Mel 2: torch.Size([645, 80])\n",
            "Mel 3: torch.Size([642, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "Loaded and processed mel shape for clip_0001: torch.Size([568, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0000: torch.Size([8])\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "\n",
            "Raw text: '42146487'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 158]\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0011: torch.Size([8])\n",
            "Raw text: '42146598'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 164]\n",
            "Loaded and processed mel shape for clip_0011: torch.Size([438, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0003: torch.Size([8])\n",
            "Raw text: '42146485'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 123]\n",
            "Loaded and processed mel shape for clip_0000: torch.Size([655, 80])\n",
            "Loaded and processed mel shape for clip_0003: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([593, 80])\n",
            "Mel 1: torch.Size([438, 80])\n",
            "Mel 2: torch.Size([912, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 912\n",
            "\n",
            "Loaded and tokenized text for clip_0007: torch.Size([8])\n",
            "Raw text: '41928558'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 164]\n",
            "Loaded and processed mel shape for clip_0007: torch.Size([506, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([568, 80])\n",
            "Mel 1: torch.Size([655, 80])\n",
            "Mel 2: torch.Size([506, 80])\n",
            "Mel 3: torch.Size([444, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 655\n",
            "\n",
            "Loaded and tokenized text for clip_0004: torch.Size([8])\n",
            "Raw text: '41928560'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0004: torch.Size([583, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "Raw text: '41928561'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0009: torch.Size([8])\n",
            "Raw text: '42691263'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 101]\n",
            "Loaded and processed mel shape for clip_0009: torch.Size([512, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0008: torch.Size([8])\n",
            "Raw text: '42691260'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 2349]\n",
            "Processing batch 0...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 655, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0008: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([583, 80])\n",
            "Mel 1: torch.Size([692, 80])\n",
            "Mel 2: torch.Size([512, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 692\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0010: torch.Size([8])\n",
            "Raw text: '42146597'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 158]\n",
            "Loaded and processed mel shape for clip_0010: torch.Size([788, 80])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0006: torch.Size([8])\n",
            "Raw text: '42691261'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 21]\n",
            "Loaded and processed mel shape for clip_0006: torch.Size([1042, 80])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "LengthRegulator output shapes:\n",
            "Raw text: '41928559'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([788, 80])\n",
            "Mel 1: torch.Size([1042, 80])\n",
            "Mel 2: torch.Size([639, 80])\n",
            "Mel 3: torch.Size([357, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1042\n",
            "\n",
            "expanded: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 7, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 7, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 7, 384])\n",
            "After positional encoding shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "After final norm shape: torch.Size([4, 7, 384])\n",
            "Final mel output shape: torch.Size([4, 7, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 7, 80])\n",
            "Training:  17% 1/6 [00:00<00:01,  3.98it/s]Processing batch 1...\n",
            "\n",
            "Loaded and tokenized text for clip_0005: torch.Size([8])\n",
            "Raw text: '42006167'\n",
            "Token IDs: [142, 37, 2349, 2349, 148, 21, 148, 158]\n",
            "Loaded and processed mel shape for clip_0005: torch.Size([599, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([599, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 599\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1083, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Processing batch 2...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 692, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 8, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 8, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "After final norm shape: torch.Size([4, 8, 384])\n",
            "Final mel output shape: torch.Size([4, 8, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 8, 80])\n",
            "Training:  50% 3/6 [00:00<00:00,  9.71it/s]Processing batch 3...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 912, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 10, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 10, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 10, 384])\n",
            "After positional encoding shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "After final norm shape: torch.Size([4, 10, 384])\n",
            "Final mel output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 10, 80])\n",
            "Processing batch 4...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1042, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Training:  83% 5/6 [00:00<00:00, 12.93it/s]Processing batch 5...\n",
            "Shapes: torch.Size([1, 8]) torch.Size([1, 599, 80]) torch.Size([1, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 6, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 6, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 6, 384])\n",
            "After positional encoding shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "After final norm shape: torch.Size([1, 6, 384])\n",
            "Final mel output shape: torch.Size([1, 6, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 6, 80])\n",
            "Training: 100% 6/6 [00:00<00:00,  9.48it/s]\n",
            "Training Loss: 0.1127\n",
            "Validation:   0% 0/6 [00:00<?, ?it/s]\n",
            "Loaded and tokenized text for clip_0000: torch.Size([8])\n",
            "Raw text: '42146487'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 158]\n",
            "\n",
            "Loaded and tokenized text for clip_0004: torch.Size([8])\n",
            "Raw text: '41928560'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0004: torch.Size([583, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0005: torch.Size([8])\n",
            "Raw text: '42006167'\n",
            "Token IDs: [142, 37, 2349, 2349, 148, 21, 148, 158]\n",
            "Loaded and processed mel shape for clip_0005: torch.Size([599, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0006: torch.Size([8])\n",
            "Raw text: '42691261'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 21]\n",
            "Loaded and processed mel shape for clip_0000: torch.Size([655, 80])\n",
            "Loaded and processed mel shape for clip_0006: torch.Size([1042, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0001: torch.Size([8])\n",
            "Loaded and tokenized text for clip_0007: torch.Size([8])\n",
            "Raw text: '41928558'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 164]\n",
            "\n",
            "Raw text: '42691259'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 123, 74]\n",
            "Loaded and processed mel shape for clip_0001: torch.Size([568, 80])\n",
            "Loaded and processed mel shape for clip_0007: torch.Size([506, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([583, 80])\n",
            "Mel 1: torch.Size([599, 80])\n",
            "Mel 2: torch.Size([1042, 80])\n",
            "Mel 3: torch.Size([506, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1042\n",
            "\n",
            "Loaded and tokenized text for clip_0002: torch.Size([8])\n",
            "Raw text: '42146600'\n",
            "Token IDs: [142, 37, 21, 142, 148, 148, 2349, 2349]\n",
            "Loaded and processed mel shape for clip_0002: torch.Size([1014, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0003: torch.Size([8])\n",
            "Raw text: '42146485'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 123]\n",
            "\n",
            "Loaded and tokenized text for clip_0012: torch.Size([8])\n",
            "Raw text: '42146486'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 148]\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "Loaded and processed mel shape for clip_0003: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([655, 80])\n",
            "Mel 1: torch.Size([568, 80])\n",
            "Mel 2: torch.Size([1014, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1014\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "Raw text: '41928559'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([645, 80])\n",
            "Mel 1: torch.Size([639, 80])\n",
            "Mel 2: torch.Size([357, 80])\n",
            "Mel 3: torch.Size([912, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 912\n",
            "\n",
            "Loaded and tokenized text for clip_0008: torch.Size([8])\n",
            "Raw text: '42691260'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0008: torch.Size([636, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0009: torch.Size([8])\n",
            "Raw text: '42691263'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 101]\n",
            "Loaded and processed mel shape for clip_0009: torch.Size([512, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0010: torch.Size([8])\n",
            "Raw text: '42146597'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 158]\n",
            "Loaded and processed mel shape for clip_0010: torch.Size([788, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0011: torch.Size([8])\n",
            "Raw text: '42146598'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 164]\n",
            "Loaded and processed mel shape for clip_0011: torch.Size([438, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([636, 80])\n",
            "Mel 1: torch.Size([512, 80])\n",
            "Mel 2: torch.Size([788, 80])\n",
            "Mel 3: torch.Size([438, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 788\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "Raw text: '41928561'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([444, 80])\n",
            "Mel 1: torch.Size([642, 80])\n",
            "Mel 2: torch.Size([692, 80])\n",
            "Mel 3: torch.Size([1083, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 11, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 11, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 11, 384])\n",
            "After positional encoding shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "After final norm shape: torch.Size([4, 11, 384])\n",
            "Final mel output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 11, 80])\n",
            "Validation:  17% 1/6 [00:00<00:01,  2.72it/s]\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([593, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 593\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 9, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 9, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 9, 384])\n",
            "After positional encoding shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "After final norm shape: torch.Size([4, 9, 384])\n",
            "Final mel output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 10, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 10, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 10, 384])\n",
            "After positional encoding shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "After final norm shape: torch.Size([4, 10, 384])\n",
            "Final mel output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 10, 80])\n",
            "Validation:  67% 4/6 [00:00<00:00,  9.73it/s]\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 6, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 6, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 6, 384])\n",
            "After positional encoding shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "After final norm shape: torch.Size([1, 6, 384])\n",
            "Final mel output shape: torch.Size([1, 6, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 6, 80])\n",
            "Validation: 100% 6/6 [00:00<00:00,  8.46it/s]\n",
            "Validation Loss: 0.0437\n",
            "\n",
            "Epoch 98/100\n",
            "Starting training epoch...\n",
            "Training:   0% 0/6 [00:00<?, ?it/s]\n",
            "Loaded and tokenized text for clip_0003: torch.Size([8])\n",
            "Raw text: '42146485'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 123]\n",
            "Loaded and processed mel shape for clip_0003: torch.Size([636, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0011: torch.Size([8])\n",
            "Raw text: '42146598'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 164]\n",
            "Loaded and processed mel shape for clip_0011: torch.Size([438, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0009: torch.Size([8])\n",
            "Raw text: '42691263'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 101]\n",
            "Loaded and processed mel shape for clip_0009: torch.Size([512, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([636, 80])\n",
            "Mel 1: torch.Size([438, 80])\n",
            "Mel 2: torch.Size([444, 80])\n",
            "Mel 3: torch.Size([512, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 636\n",
            "\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "\n",
            "Loaded and tokenized text for clip_0007: torch.Size([8])\n",
            "Raw text: '41928558'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 164]\n",
            "Loaded and processed mel shape for clip_0007: torch.Size([506, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0010: torch.Size([8])\n",
            "Raw text: '42146597'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 158]\n",
            "Loaded and processed mel shape for clip_0010: torch.Size([788, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([506, 80])\n",
            "Mel 1: torch.Size([639, 80])\n",
            "Mel 2: torch.Size([788, 80])\n",
            "Mel 3: torch.Size([642, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 788\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "Raw text: '41928559'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0004: torch.Size([8])\n",
            "Raw text: '41928560'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0004: torch.Size([583, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0002: torch.Size([8])\n",
            "Raw text: '42146600'\n",
            "Token IDs: [142, 37, 21, 142, 148, 148, 2349, 2349]\n",
            "Loaded and processed mel shape for clip_0002: torch.Size([1014, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "Raw text: '41928561'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([357, 80])\n",
            "Mel 1: torch.Size([583, 80])\n",
            "Mel 2: torch.Size([1014, 80])\n",
            "Mel 3: torch.Size([692, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1014\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0006: torch.Size([8])\n",
            "Raw text: '42691261'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 21]\n",
            "Loaded and processed mel shape for clip_0006: torch.Size([1042, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0008: torch.Size([8])\n",
            "Raw text: '42691260'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0008: torch.Size([636, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0001: torch.Size([8])\n",
            "Raw text: '42691259'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 123, 74]\n",
            "Loaded and processed mel shape for clip_0001: torch.Size([568, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([593, 80])\n",
            "Mel 1: torch.Size([1042, 80])\n",
            "Mel 2: torch.Size([636, 80])\n",
            "Mel 3: torch.Size([568, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1042\n",
            "Processing batch 0...\n",
            "\n",
            "Loaded and tokenized text for clip_0012: torch.Size([8])Shapes: torch.Size([4, 8]) torch.Size([4, 636, 80]) torch.Size([4, 8])\n",
            "\n",
            "Raw text: '42146486'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 148]\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0005: torch.Size([8])\n",
            "Raw text: '42006167'\n",
            "Token IDs: [142, 37, 2349, 2349, 148, 21, 148, 158]\n",
            "Loaded and processed mel shape for clip_0005: torch.Size([599, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([645, 80])\n",
            "Mel 1: torch.Size([912, 80])\n",
            "Mel 2: torch.Size([599, 80])\n",
            "Mel 3: torch.Size([1083, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 7, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 7, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 7, 384])\n",
            "After positional encoding shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "After final norm shape: torch.Size([4, 7, 384])\n",
            "Final mel output shape: torch.Size([4, 7, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 7, 80])\n",
            "Training:  17% 1/6 [00:00<00:01,  4.50it/s]Processing batch 1...\n",
            "\n",
            "Loaded and tokenized text for clip_0000: torch.Size([8])\n",
            "Raw text: '42146487'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 158]\n",
            "Loaded and processed mel shape for clip_0000: torch.Size([655, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([655, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 655\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 788, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 9, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 9, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 9, 384])\n",
            "After positional encoding shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "After final norm shape: torch.Size([4, 9, 384])\n",
            "Final mel output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 9, 80])\n",
            "Processing batch 2...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1042, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Processing batch 3...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1014, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 11, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 11, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 11, 384])\n",
            "After positional encoding shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "After final norm shape: torch.Size([4, 11, 384])\n",
            "Final mel output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 11, 80])\n",
            "Training:  67% 4/6 [00:00<00:00, 12.35it/s]Processing batch 4...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1083, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Processing batch 5...\n",
            "Shapes: torch.Size([1, 8]) torch.Size([1, 655, 80]) torch.Size([1, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 7, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 7, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 7, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 7, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 7, 384])\n",
            "After positional encoding shape: torch.Size([1, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 7, 384])\n",
            "FFTBlock output shape: torch.Size([1, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 7, 384])\n",
            "FFTBlock output shape: torch.Size([1, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 7, 384])\n",
            "FFTBlock output shape: torch.Size([1, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 7, 384])\n",
            "FFTBlock output shape: torch.Size([1, 7, 384])\n",
            "After final norm shape: torch.Size([1, 7, 384])\n",
            "Final mel output shape: torch.Size([1, 7, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 7, 80])\n",
            "Training: 100% 6/6 [00:00<00:00, 12.55it/s]\n",
            "Training Loss: 0.0940\n",
            "Validation:   0% 0/6 [00:00<?, ?it/s]\n",
            "Loaded and tokenized text for clip_0000: torch.Size([8])\n",
            "Raw text: '42146487'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 158]\n",
            "Loaded and processed mel shape for clip_0000: torch.Size([655, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0001: torch.Size([8])\n",
            "Raw text: '42691259'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 123, 74]\n",
            "Loaded and processed mel shape for clip_0001: torch.Size([568, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0002: torch.Size([8])\n",
            "Raw text: '42146600'\n",
            "Token IDs: [142, 37, 21, 142, 148, 148, 2349, 2349]\n",
            "Loaded and processed mel shape for clip_0002: torch.Size([1014, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0003: torch.Size([8])\n",
            "Raw text: '42146485'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 123]\n",
            "Loaded and processed mel shape for clip_0003: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([655, 80])\n",
            "Mel 1: torch.Size([568, 80])\n",
            "Mel 2: torch.Size([1014, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1014\n",
            "\n",
            "Loaded and tokenized text for clip_0008: torch.Size([8])\n",
            "Raw text: '42691260'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0008: torch.Size([636, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0009: torch.Size([8])\n",
            "Raw text: '42691263'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 101]\n",
            "\n",
            "Loaded and tokenized text for clip_0004: torch.Size([8])\n",
            "Raw text: '41928560'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0009: torch.Size([512, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0010: torch.Size([8])\n",
            "Raw text: '42146597'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 158]\n",
            "Loaded and processed mel shape for clip_0010: torch.Size([788, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0011: torch.Size([8])\n",
            "Raw text: '42146598'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 164]\n",
            "Loaded and processed mel shape for clip_0004: torch.Size([583, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0005: torch.Size([8])\n",
            "Raw text: '42006167'\n",
            "Token IDs: [142, 37, 2349, 2349, 148, 21, 148, 158]\n",
            "Loaded and processed mel shape for clip_0011: torch.Size([438, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([636, 80])\n",
            "Mel 1: torch.Size([512, 80])\n",
            "Mel 2: torch.Size([788, 80])\n",
            "Mel 3: torch.Size([438, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 788\n",
            "Loaded and processed mel shape for clip_0005: torch.Size([599, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0006: torch.Size([8])\n",
            "Raw text: '42691261'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 21]\n",
            "Loaded and processed mel shape for clip_0006: torch.Size([1042, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0007: torch.Size([8])\n",
            "Raw text: '41928558'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 164]\n",
            "Loaded and processed mel shape for clip_0007: torch.Size([506, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([583, 80])\n",
            "Mel 1: torch.Size([599, 80])\n",
            "Mel 2: torch.Size([1042, 80])\n",
            "Mel 3: torch.Size([506, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1042\n",
            "\n",
            "Loaded and tokenized text for clip_0012: torch.Size([8])\n",
            "Raw text: '42146486'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 148]\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "\n",
            "FastSpeech2 input shapes:Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "Raw text: '41928559'\n",
            "\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([645, 80])\n",
            "Mel 1: torch.Size([639, 80])\n",
            "Mel 2: torch.Size([357, 80])\n",
            "Mel 3: torch.Size([912, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 912\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "Raw text: '41928561'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([444, 80])\n",
            "Mel 1: torch.Size([642, 80])\n",
            "Mel 2: torch.Size([692, 80])\n",
            "Mel 3: torch.Size([1083, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 11, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 11, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 11, 384])\n",
            "After positional encoding shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "After final norm shape: torch.Size([4, 11, 384])\n",
            "Final mel output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 11, 80])\n",
            "Validation:  17% 1/6 [00:00<00:00,  5.57it/s]\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([593, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 593\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 9, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 9, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 9, 384])\n",
            "After positional encoding shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "After final norm shape: torch.Size([4, 9, 384])\n",
            "Final mel output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 10, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 10, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 10, 384])\n",
            "After positional encoding shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "After final norm shape: torch.Size([4, 10, 384])\n",
            "Final mel output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 6, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 6, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 6, 384])\n",
            "After positional encoding shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "After final norm shape: torch.Size([1, 6, 384])\n",
            "Final mel output shape: torch.Size([1, 6, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 6, 80])\n",
            "Validation: 100% 6/6 [00:00<00:00, 19.02it/s]\n",
            "Validation Loss: 0.0370\n",
            "\n",
            "Epoch 99/100\n",
            "Starting training epoch...\n",
            "Training:   0% 0/6 [00:00<?, ?it/s]\n",
            "Loaded and tokenized text for clip_0012: torch.Size([8])\n",
            "Raw text: '42146486'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 148]\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0000: torch.Size([8])\n",
            "Raw text: '42146487'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 158]\n",
            "Loaded and processed mel shape for clip_0000: torch.Size([655, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "Raw text: '41928559'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([645, 80])\n",
            "Mel 1: torch.Size([655, 80])\n",
            "Mel 2: torch.Size([444, 80])\n",
            "Mel 3: torch.Size([357, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 655\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "\n",
            "Loaded and tokenized text for clip_0003: torch.Size([8])Raw text: '41928561'\n",
            "\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "Raw text: '42146485'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 123]\n",
            "Loaded and processed mel shape for clip_0003: torch.Size([636, 80])\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0006: torch.Size([8])\n",
            "Raw text: '42691261'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 21]\n",
            "\n",
            "Loaded and tokenized text for clip_0007: torch.Size([8])\n",
            "Raw text: '41928558'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 164]\n",
            "Loaded and processed mel shape for clip_0006: torch.Size([1042, 80])\n",
            "Loaded and processed mel shape for clip_0007: torch.Size([506, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([1083, 80])\n",
            "Mel 1: torch.Size([912, 80])\n",
            "Mel 2: torch.Size([692, 80])\n",
            "Mel 3: torch.Size([506, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0008: torch.Size([8])\n",
            "Raw text: '42691260'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0008: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([636, 80])\n",
            "Mel 1: torch.Size([1042, 80])\n",
            "Mel 2: torch.Size([639, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1042\n",
            "\n",
            "Loaded and tokenized text for clip_0001: torch.Size([8])\n",
            "Raw text: '42691259'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 123, 74]\n",
            "Loaded and processed mel shape for clip_0001: torch.Size([568, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0002: torch.Size([8])\n",
            "Raw text: '42146600'\n",
            "Token IDs: [142, 37, 21, 142, 148, 148, 2349, 2349]\n",
            "Loaded and processed mel shape for clip_0002: torch.Size([1014, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0004: torch.Size([8])\n",
            "Raw text: '41928560'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0004: torch.Size([583, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([568, 80])\n",
            "Mel 1: torch.Size([1014, 80])\n",
            "Mel 2: torch.Size([593, 80])\n",
            "Mel 3: torch.Size([583, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1014\n",
            "Processing batch 0...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 655, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "\n",
            "Loaded and tokenized text for clip_0010: torch.Size([8])\n",
            "Raw text: '42146597'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 158]\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0010: torch.Size([788, 80])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0009: torch.Size([8])\n",
            "Raw text: '42691263'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 101]\n",
            "Loaded and processed mel shape for clip_0009: torch.Size([512, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0011: torch.Size([8])\n",
            "Raw text: '42146598'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 164]\n",
            "Loaded and processed mel shape for clip_0011: torch.Size([438, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([788, 80])\n",
            "Mel 1: torch.Size([512, 80])\n",
            "Mel 2: torch.Size([438, 80])\n",
            "Mel 3: torch.Size([642, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 788\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 7, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 7, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 7, 384])\n",
            "After positional encoding shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "After final norm shape: torch.Size([4, 7, 384])\n",
            "Final mel output shape: torch.Size([4, 7, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 7, 80])\n",
            "Training:  17% 1/6 [00:00<00:00,  7.22it/s]Processing batch 1...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1083, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Loaded and tokenized text for clip_0005: torch.Size([8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "Raw text: '42006167'\n",
            "Token IDs: [142, 37, 2349, 2349, 148, 21, 148, 158]\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0005: torch.Size([599, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([599, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 599\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Processing batch 2...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1042, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Processing batch 3...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1014, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 11, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 11, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 11, 384])\n",
            "After positional encoding shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "After final norm shape: torch.Size([4, 11, 384])\n",
            "Final mel output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 11, 80])\n",
            "Processing batch 4...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 788, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 9, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 9, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 9, 384])\n",
            "After positional encoding shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "After final norm shape: torch.Size([4, 9, 384])\n",
            "Final mel output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 9, 80])\n",
            "Training:  83% 5/6 [00:00<00:00, 21.80it/s]Processing batch 5...\n",
            "Shapes: torch.Size([1, 8]) torch.Size([1, 599, 80]) torch.Size([1, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 6, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 6, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 6, 384])\n",
            "After positional encoding shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "After final norm shape: torch.Size([1, 6, 384])\n",
            "Final mel output shape: torch.Size([1, 6, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 6, 80])\n",
            "Training: 100% 6/6 [00:00<00:00, 18.02it/s]\n",
            "Training Loss: 0.0924\n",
            "Validation:   0% 0/6 [00:00<?, ?it/s]\n",
            "Loaded and tokenized text for clip_0000: torch.Size([8])\n",
            "Raw text: '42146487'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 158]\n",
            "Loaded and processed mel shape for clip_0000: torch.Size([655, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0001: torch.Size([8])\n",
            "Raw text: '42691259'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 123, 74]\n",
            "Loaded and processed mel shape for clip_0001: torch.Size([568, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0002: torch.Size([8])\n",
            "Raw text: '42146600'\n",
            "Token IDs: [142, 37, 21, 142, 148, 148, 2349, 2349]\n",
            "\n",
            "Loaded and tokenized text for clip_0004: torch.Size([8])\n",
            "Raw text: '41928560'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0002: torch.Size([1014, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0003: torch.Size([8])\n",
            "Raw text: '42146485'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 123]\n",
            "Loaded and processed mel shape for clip_0003: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([655, 80])\n",
            "Mel 1: torch.Size([568, 80])\n",
            "Mel 2: torch.Size([1014, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1014\n",
            "Loaded and processed mel shape for clip_0004: torch.Size([583, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0005: torch.Size([8])\n",
            "Raw text: '42006167'\n",
            "Token IDs: [142, 37, 2349, 2349, 148, 21, 148, 158]\n",
            "Loaded and processed mel shape for clip_0005: torch.Size([599, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0006: torch.Size([8])\n",
            "Raw text: '42691261'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 21]\n",
            "\n",
            "Loaded and tokenized text for clip_0008: torch.Size([8])\n",
            "Raw text: '42691260'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0006: torch.Size([1042, 80])\n",
            "Loaded and processed mel shape for clip_0008: torch.Size([636, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0007: torch.Size([8])\n",
            "Raw text: '41928558'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 164]\n",
            "\n",
            "Loaded and tokenized text for clip_0009: torch.Size([8])\n",
            "Raw text: '42691263'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 101]\n",
            "Loaded and processed mel shape for clip_0007: torch.Size([506, 80])\n",
            "Loaded and processed mel shape for clip_0009: torch.Size([512, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([583, 80])\n",
            "Mel 1: torch.Size([599, 80])\n",
            "Mel 2: torch.Size([1042, 80])\n",
            "Mel 3: torch.Size([506, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1042\n",
            "\n",
            "Loaded and tokenized text for clip_0010: torch.Size([8])\n",
            "Raw text: '42146597'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 158]\n",
            "Loaded and processed mel shape for clip_0010: torch.Size([788, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0011: torch.Size([8])\n",
            "Raw text: '42146598'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 164]\n",
            "Loaded and processed mel shape for clip_0011: torch.Size([438, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([636, 80])\n",
            "Mel 1: torch.Size([512, 80])\n",
            "Mel 2: torch.Size([788, 80])\n",
            "Mel 3: torch.Size([438, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 788\n",
            "\n",
            "Loaded and tokenized text for clip_0012: torch.Size([8])\n",
            "Raw text: '42146486'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 148]\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "Raw text: '41928559'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([645, 80])\n",
            "Mel 1: torch.Size([639, 80])\n",
            "Mel 2: torch.Size([357, 80])\n",
            "Mel 3: torch.Size([912, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 912\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])\n",
            "FastSpeech2 input shapes:\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "Raw text: '41928561'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([444, 80])\n",
            "Mel 1: torch.Size([642, 80])\n",
            "Mel 2: torch.Size([692, 80])\n",
            "Mel 3: torch.Size([1083, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 11, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 11, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 11, 384])\n",
            "After positional encoding shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "After final norm shape: torch.Size([4, 11, 384])\n",
            "Final mel output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([593, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 593\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Validation:  33% 2/6 [00:00<00:00, 18.89it/s]\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 9, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 9, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 9, 384])\n",
            "After positional encoding shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "After final norm shape: torch.Size([4, 9, 384])\n",
            "Final mel output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 10, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 10, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 10, 384])\n",
            "After positional encoding shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "After final norm shape: torch.Size([4, 10, 384])\n",
            "Final mel output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 6, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 6, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 6, 384])\n",
            "After positional encoding shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "After final norm shape: torch.Size([1, 6, 384])\n",
            "Final mel output shape: torch.Size([1, 6, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 6, 80])\n",
            "Validation: 100% 6/6 [00:00<00:00, 31.24it/s]\n",
            "Validation Loss: 0.0310\n",
            "Saved new best model!\n",
            "\n",
            "Epoch 100/100\n",
            "Starting training epoch...\n",
            "Training:   0% 0/6 [00:00<?, ?it/s]\n",
            "Loaded and tokenized text for clip_0007: torch.Size([8])\n",
            "Raw text: '41928558'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 164]\n",
            "Loaded and processed mel shape for clip_0007: torch.Size([506, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0010: torch.Size([8])\n",
            "Raw text: '42146597'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 158]\n",
            "Loaded and processed mel shape for clip_0010: torch.Size([788, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0006: torch.Size([8])\n",
            "Raw text: '42691261'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 21]\n",
            "Loaded and processed mel shape for clip_0006: torch.Size([1042, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0012: torch.Size([8])\n",
            "Raw text: '42146486'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 148]\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([506, 80])\n",
            "Mel 1: torch.Size([788, 80])\n",
            "Mel 2: torch.Size([1042, 80])\n",
            "Mel 3: torch.Size([645, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1042\n",
            "\n",
            "Loaded and tokenized text for clip_0009: torch.Size([8])\n",
            "Raw text: '42691263'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 101]\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0005: torch.Size([8])\n",
            "Raw text: '42006167'\n",
            "Token IDs: [142, 37, 2349, 2349, 148, 21, 148, 158]\n",
            "Loaded and processed mel shape for clip_0005: torch.Size([599, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0001: torch.Size([8])\n",
            "Raw text: '42691259'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 123, 74]\n",
            "Loaded and processed mel shape for clip_0001: torch.Size([568, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0008: torch.Size([8])\n",
            "Raw text: '42691260'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0009: torch.Size([512, 80])\n",
            "Loaded and processed mel shape for clip_0008: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([444, 80])\n",
            "Mel 1: torch.Size([599, 80])\n",
            "Mel 2: torch.Size([568, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 636\n",
            "\n",
            "Loaded and tokenized text for clip_0011: torch.Size([8])\n",
            "Raw text: '42146598'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 164]\n",
            "Loaded and processed mel shape for clip_0011: torch.Size([438, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0004: torch.Size([8])\n",
            "Raw text: '41928560'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0004: torch.Size([583, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0000: torch.Size([8])\n",
            "Raw text: '42146487'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 158]\n",
            "Loaded and processed mel shape for clip_0000: torch.Size([655, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([512, 80])\n",
            "Mel 1: torch.Size([438, 80])\n",
            "Mel 2: torch.Size([583, 80])\n",
            "Mel 3: torch.Size([655, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 655\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "Raw text: '41928559'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "Processing batch 0...\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0003: torch.Size([8])\n",
            "Raw text: '42146485'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 123]\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1042, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "Loaded and tokenized text for clip_0002: torch.Size([8])\n",
            "Loaded and processed mel shape for clip_0003: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([639, 80])\n",
            "Mel 1: torch.Size([357, 80])\n",
            "Mel 2: torch.Size([642, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 642\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Raw text: '42146600'\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "Token IDs: [142, 37, 21, 142, 148, 148, 2349, 2349]\n",
            "Loaded and processed mel shape for clip_0002: torch.Size([1014, 80])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "Raw text: '41928561'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([1014, 80])\n",
            "Mel 1: torch.Size([593, 80])\n",
            "Mel 2: torch.Size([912, 80])\n",
            "Mel 3: torch.Size([692, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1014\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Training:  17% 1/6 [00:00<00:00,  7.90it/s]Processing batch 1...\n",
            "\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 655, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([1083, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 7, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 7, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 7, 384])\n",
            "After positional encoding shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "After final norm shape: torch.Size([4, 7, 384])\n",
            "Final mel output shape: torch.Size([4, 7, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 7, 80])\n",
            "Processing batch 2...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 636, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 7, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 7, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 7, 384])\n",
            "After positional encoding shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "After final norm shape: torch.Size([4, 7, 384])\n",
            "Final mel output shape: torch.Size([4, 7, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 7, 80])\n",
            "Processing batch 3...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 642, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 7, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 7, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 7, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 7, 384])\n",
            "After positional encoding shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 7, 384])\n",
            "FFTBlock output shape: torch.Size([4, 7, 384])\n",
            "After final norm shape: torch.Size([4, 7, 384])\n",
            "Final mel output shape: torch.Size([4, 7, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 7, 80])\n",
            "Processing batch 4...\n",
            "Shapes: torch.Size([4, 8]) torch.Size([4, 1014, 80]) torch.Size([4, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 11, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 11, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 11, 384])\n",
            "After positional encoding shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "After final norm shape: torch.Size([4, 11, 384])\n",
            "Final mel output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 11, 80])\n",
            "Training:  83% 5/6 [00:00<00:00, 22.40it/s]Processing batch 5...\n",
            "Shapes: torch.Size([1, 8]) torch.Size([1, 1083, 80]) torch.Size([1, 8])\n",
            "Forward pass...\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 12, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 12, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 12, 384])\n",
            "After positional encoding shape: torch.Size([1, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 12, 384])\n",
            "FFTBlock output shape: torch.Size([1, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 12, 384])\n",
            "FFTBlock output shape: torch.Size([1, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 12, 384])\n",
            "FFTBlock output shape: torch.Size([1, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 12, 384])\n",
            "FFTBlock output shape: torch.Size([1, 12, 384])\n",
            "After final norm shape: torch.Size([1, 12, 384])\n",
            "Final mel output shape: torch.Size([1, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 12, 80])\n",
            "Training: 100% 6/6 [00:00<00:00, 19.56it/s]\n",
            "Training Loss: 0.0939\n",
            "Validation:   0% 0/6 [00:00<?, ?it/s]\n",
            "Loaded and tokenized text for clip_0000: torch.Size([8])\n",
            "Raw text: '42146487'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 158]\n",
            "Loaded and processed mel shape for clip_0000: torch.Size([655, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0001: torch.Size([8])\n",
            "Raw text: '42691259'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 123, 74]\n",
            "Loaded and processed mel shape for clip_0001: torch.Size([568, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0002: torch.Size([8])\n",
            "Raw text: '42146600'\n",
            "Token IDs: [142, 37, 21, 142, 148, 148, 2349, 2349]\n",
            "Loaded and processed mel shape for clip_0002: torch.Size([1014, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0004: torch.Size([8])\n",
            "Raw text: '41928560'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 2349]\n",
            "\n",
            "Loaded and tokenized text for clip_0003: torch.Size([8])\n",
            "Raw text: '42146485'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 123]\n",
            "Loaded and processed mel shape for clip_0003: torch.Size([636, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([655, 80])\n",
            "Mel 1: torch.Size([568, 80])\n",
            "Mel 2: torch.Size([1014, 80])\n",
            "Mel 3: torch.Size([636, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1014\n",
            "Loaded and processed mel shape for clip_0004: torch.Size([583, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0005: torch.Size([8])\n",
            "Raw text: '42006167'\n",
            "Token IDs: [142, 37, 2349, 2349, 148, 21, 148, 158]\n",
            "\n",
            "Loaded and tokenized text for clip_0008: torch.Size([8])\n",
            "Raw text: '42691260'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 2349]\n",
            "Loaded and processed mel shape for clip_0005: torch.Size([599, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0006: torch.Size([8])\n",
            "Raw text: '42691261'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 21]\n",
            "Loaded and processed mel shape for clip_0008: torch.Size([636, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0009: torch.Size([8])\n",
            "Raw text: '42691263'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 101]\n",
            "Loaded and processed mel shape for clip_0006: torch.Size([1042, 80])\n",
            "Loaded and processed mel shape for clip_0009: torch.Size([512, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0007: torch.Size([8])\n",
            "Raw text: '41928558'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 164]\n",
            "\n",
            "Loaded and tokenized text for clip_0010: torch.Size([8])\n",
            "Raw text: '42146597'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 158]\n",
            "Loaded and processed mel shape for clip_0010: torch.Size([788, 80])\n",
            "Loaded and processed mel shape for clip_0007: torch.Size([506, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([583, 80])\n",
            "Mel 1: torch.Size([599, 80])\n",
            "Mel 2: torch.Size([1042, 80])\n",
            "Mel 3: torch.Size([506, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1042\n",
            "\n",
            "Loaded and tokenized text for clip_0011: torch.Size([8])\n",
            "Raw text: '42146598'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 164]\n",
            "Loaded and processed mel shape for clip_0011: torch.Size([438, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([636, 80])\n",
            "Mel 1: torch.Size([512, 80])\n",
            "Mel 2: torch.Size([788, 80])\n",
            "Mel 3: torch.Size([438, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 788\n",
            "\n",
            "Loaded and tokenized text for clip_0012: torch.Size([8])\n",
            "Raw text: '42146486'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 148]\n",
            "Loaded and processed mel shape for clip_0012: torch.Size([645, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0013: torch.Size([8])\n",
            "Raw text: '42691262'\n",
            "Token IDs: [142, 37, 148, 74, 21, 37, 148, 37]\n",
            "Loaded and processed mel shape for clip_0013: torch.Size([639, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0014: torch.Size([8])\n",
            "Raw text: '41928559'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 123, 74]\n",
            "Loaded and processed mel shape for clip_0014: torch.Size([357, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0015: torch.Size([8])\n",
            "Raw text: '42146596'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 148]\n",
            "Loaded and processed mel shape for clip_0015: torch.Size([912, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([645, 80])\n",
            "Mel 1: torch.Size([639, 80])\n",
            "Mel 2: torch.Size([357, 80])\n",
            "Mel 3: torch.Size([912, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 912\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "\n",
            "Loaded and tokenized text for clip_0016: torch.Size([8])After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Raw text: '41928562'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 37]\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0016: torch.Size([444, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0017: torch.Size([8])\n",
            "Raw text: '42146488'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 164]\n",
            "Loaded and processed mel shape for clip_0017: torch.Size([642, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0018: torch.Size([8])\n",
            "Raw text: '41928561'\n",
            "Token IDs: [142, 21, 74, 37, 164, 123, 148, 21]\n",
            "Loaded and processed mel shape for clip_0018: torch.Size([692, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0019: torch.Size([8])\n",
            "Raw text: '42146599'\n",
            "Token IDs: [142, 37, 21, 142, 148, 123, 74, 74]\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "Loaded and processed mel shape for clip_0019: torch.Size([1083, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "Text 1: torch.Size([8])\n",
            "Text 2: torch.Size([8])\n",
            "Text 3: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([444, 80])\n",
            "Mel 1: torch.Size([642, 80])\n",
            "Mel 2: torch.Size([692, 80])\n",
            "Mel 3: torch.Size([1083, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 1083\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 11, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 11, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 11, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 11, 384])\n",
            "After positional encoding shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 11, 384])\n",
            "FFTBlock output shape: torch.Size([4, 11, 384])\n",
            "After final norm shape: torch.Size([4, 11, 384])\n",
            "Final mel output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 11, 80])\n",
            "\n",
            "Loaded and tokenized text for clip_0020: torch.Size([8])\n",
            "Raw text: '42146489'\n",
            "Token IDs: [142, 37, 21, 142, 148, 142, 164, 74]\n",
            "Loaded and processed mel shape for clip_0020: torch.Size([593, 80])\n",
            "\n",
            "Text shapes in batch:\n",
            "Text 0: torch.Size([8])\n",
            "\n",
            "Mel shapes in batch:\n",
            "Mel 0: torch.Size([593, 80])\n",
            "Max text length: 8\n",
            "Max mel length: 593\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "Validation:  33% 2/6 [00:00<00:00, 17.52it/s]\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 9, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 9, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 9, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 9, 384])\n",
            "After positional encoding shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 9, 384])\n",
            "FFTBlock output shape: torch.Size([4, 9, 384])\n",
            "After final norm shape: torch.Size([4, 9, 384])\n",
            "Final mel output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 9, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 10, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 10, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 10, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 10, 384])\n",
            "After positional encoding shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 10, 384])\n",
            "FFTBlock output shape: torch.Size([4, 10, 384])\n",
            "After final norm shape: torch.Size([4, 10, 384])\n",
            "Final mel output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 10, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([4, 8])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([4, 8])\n",
            "After embedding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 8, 384])\n",
            "After positional encoding shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 8, 384])\n",
            "FFTBlock output shape: torch.Size([4, 8, 384])\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([4, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([4, 8, 384])\n",
            "duration_target: torch.Size([4, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([4, 12, 384])\n",
            "duration_pred: torch.Size([4, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([4, 12, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([4, 12, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([4, 12, 384])\n",
            "After positional encoding shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([4, 12, 384])\n",
            "FFTBlock output shape: torch.Size([4, 12, 384])\n",
            "After final norm shape: torch.Size([4, 12, 384])\n",
            "Final mel output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([4, 12, 80])\n",
            "\n",
            "FastSpeech2 input shapes:\n",
            "src: torch.Size([1, 8])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "Encoder input shape: torch.Size([1, 8])\n",
            "After embedding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 8, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 8, 384])\n",
            "After positional encoding shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 8, 384])\n",
            "FFTBlock output shape: torch.Size([1, 8, 384])\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "Encoder output shape: torch.Size([1, 8, 384])\n",
            "\n",
            "LengthRegulator input shapes:\n",
            "x: torch.Size([1, 8, 384])\n",
            "duration_target: torch.Size([1, 8])\n",
            "\n",
            "LengthRegulator output shapes:\n",
            "expanded: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "After length regulation shapes:\n",
            "length_regulated: torch.Size([1, 6, 384])\n",
            "duration_pred: torch.Size([1, 8])\n",
            "\n",
            "Decoder input shape: torch.Size([1, 6, 384])\n",
            "\n",
            "PositionalEncoding input shape: torch.Size([1, 6, 384])\n",
            "pe shape: torch.Size([1, 10000, 384])\n",
            "PositionalEncoding output shape: torch.Size([1, 6, 384])\n",
            "After positional encoding shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "\n",
            "FFTBlock input shape: torch.Size([1, 6, 384])\n",
            "FFTBlock output shape: torch.Size([1, 6, 384])\n",
            "After final norm shape: torch.Size([1, 6, 384])\n",
            "Final mel output shape: torch.Size([1, 6, 80])\n",
            "\n",
            "Decoder output shape: torch.Size([1, 6, 80])\n",
            "Validation: 100% 6/6 [00:00<00:00, 31.99it/s]\n",
            "Validation Loss: 0.0321\n"
          ]
        }
      ]
    }
  ]
}