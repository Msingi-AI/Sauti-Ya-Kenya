#!/usr/bin/env python3
"""Run the Fish Speech -> CosyVoice distillation scaffold using `configs/distill.yaml`.

This script is a smoke-test scaffold â€” it follows the user's provided pseudocode
and stops after 100 streaming steps. Replace model wrappers and data processing
with full training components for production runs.
"""
import yaml
import torch
import torch.nn as nn
from datasets import load_dataset
from transformers import AutoModel
from src.sauti.precompute import precompute_teacher_activations
from src.sauti.losses import mel_l1_loss, hard_text_loss
from src.sauti.distillation_loss import SwahiliDistillationLoss
import math
import glob
import numpy as np
import os
import logging


def load_config(path):
    with open(path, 'r') as f:
        return yaml.safe_load(f)


def run_distillation():
    cfg = load_config("configs/distill.yaml")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logging.info(f"ðŸš€ Starting Distillation on {device}...")

    # 1. Load the frozen Teacher (Fish Speech 1.5)
    logging.info(f"Loading Teacher: {cfg['teacher']['model_id']}...")
    teacher = AutoModel.from_pretrained(cfg['teacher']['model_id'], trust_remote_code=True).to(device)
    teacher.eval()
    for param in teacher.parameters():
        param.requires_grad = False

    # 2. Load the Student (CosyVoice 2)
    logging.info(f"Loading Student: {cfg['student']['model_id']}...")
    student = AutoModel.from_pretrained(cfg['student']['model_id'], trust_remote_code=True).to(device)

    # 3. The "Bridge": Projection Layer for Dimensionality Mismatch
    projection_layer = nn.Linear(cfg['teacher']['hidden_size'], cfg['student']['hidden_size']).to(device)

    # 4. WAXAL Data Loader (streaming for smoke test)
    logging.info(f"Loading WAXAL ({cfg['data']['subset']})...")
    try:
        dataset = load_dataset(cfg['data']['train_dataset'], cfg['data']['subset'], split="train", streaming=True)
    except Exception:
        logging.warning("Could not stream dataset; attempting non-stream load for smoke test")
        dataset = load_dataset(cfg['data']['train_dataset'], cfg['data']['subset'], split="train")

    # Ensure teacher activations are precomputed (for a proper distillation loop)
    act_dir = os.path.join(cfg['project'].get('output_dir', 'checkpoints'), 'teacher_activations')
    manifest = os.path.join(act_dir, 'manifest.jsonl')
    if not os.path.exists(manifest):
        logging.info("Teacher activations not found; precomputing a small cache (smoke-test)")
        precompute_teacher_activations(cfg['data']['train_dataset'], cfg['data']['subset'], out_dir=act_dir, max_items=200)

    # load list of activation files for quick access
    activation_files = sorted(glob.glob(os.path.join(act_dir, 'act_*.npz')))

    # 5. Optimizer & Loss
    # Create small projection heads to produce logits from hidden states for smoke tests
    vocab_size = cfg.get('distillation', {}).get('vocab_size', 1000)
    student_proj = nn.Linear(cfg['student']['hidden_size'], vocab_size).to(device)
    teacher_proj = nn.Linear(cfg['teacher']['hidden_size'], vocab_size).to(device)
    # Teacher projection should be frozen (we treat teacher as fixed)
    for p in teacher_proj.parameters():
        p.requires_grad = False

    optimizer = torch.optim.AdamW(
        list(student.parameters()) + list(projection_layer.parameters()) + list(student_proj.parameters()),
        lr=cfg['training']['learning_rate']
    )

    # Distillation criterion
    crit = SwahiliDistillationLoss(temperature=cfg['distillation'].get('temperature', 2.0), alpha=cfg['distillation'].get('alpha_hard', 0.5))

    student.train()
    step = 0
    for example in dataset:
        step += 1
        # NOTE: WAXAL examples may not have `input_ids` directly â€” this is a scaffold.
        # Users must replace the following with proper feature extraction/tokenization.
        batch_inputs = example.get('input_ids') or example.get('input') or example.get('text')
        if batch_inputs is None:
            # Skip examples that don't match scaffold fields
            if step >= 100:
                break
            continue

        # Convert batch_inputs to dummy tensor when necessary (smoke test)
        if not torch.is_tensor(batch_inputs):
            # create a tiny tensor to allow model forward (shape-dependent)
            try:
                batch_tensor = torch.tensor([[1, 2, 3]], dtype=torch.long).to(device)
            except Exception:
                batch_tensor = torch.zeros((1, 1), dtype=torch.long).to(device)
        else:
            batch_tensor = batch_inputs.to(device)

        # A. Teacher hidden states: load from activation cache when available
        teacher_hidden = None
        if activation_files:
            try:
                act_path = activation_files[(step - 1) % len(activation_files)]
                npz = np.load(act_path)
                th = npz.get('teacher_hidden')
                if th is not None:
                    teacher_hidden = torch.from_numpy(th).to(device)
            except Exception:
                logging.exception("Failed to load cached activation %s", act_path)

        if teacher_hidden is None:
            with torch.no_grad():
                try:
                    teacher_outputs = teacher(batch_tensor)
                    teacher_hidden = getattr(teacher_outputs, 'last_hidden_state', None) or teacher_outputs[0]
                except Exception:
                    teacher_hidden = torch.randn((1, 10, cfg['teacher']['hidden_size']), device=device)

        # B. Student forward
        try:
            student_outputs = student(batch_tensor)
            student_hidden = getattr(student_outputs, 'last_hidden_state', None) or student_outputs[0]
        except Exception:
            student_hidden = torch.randn((1, 10, cfg['student']['hidden_size']), device=device)

        # C. Project teacher hidden states and compute representation loss
        projected_teacher = projection_layer(teacher_hidden[..., :cfg['teacher']['hidden_size']])
        loss_repr = nn.functional.mse_loss(student_hidden, projected_teacher)

        # Convert hidden states to logits for distillation criterion
        # student_hidden: (B, T, Hs) -> logits (B, T, V)
        try:
            student_logits = student_proj(student_hidden)
        except Exception:
            B, T, Hs = student_hidden.shape
            student_logits = torch.randn((B, T, vocab_size), device=device)

        try:
            teacher_logits = teacher_proj(teacher_hidden[..., :cfg['teacher']['hidden_size']])
        except Exception:
            B, T, Ht = teacher_hidden.shape
            teacher_logits = torch.randn((B, T, vocab_size), device=device)

        # D. Optional mel loss / hard-target loss (best-effort placeholders)
        mel_loss = torch.tensor(0.0, device=device)
        hard_loss = torch.tensor(0.0, device=device)
        try:
            # If example contains audio array, compute mel target and apply mel L1 loss
            audio = None
            if isinstance(example.get('audio'), dict):
                audio = example['audio'].get('array')
            elif isinstance(example.get('audio'), (list, tuple)):
                audio = example.get('audio')
            if audio is not None:
                target_mel = mel_spect = None
                try:
                    # use mel_spectrogram from helper (numpy)
                    from src.sauti.losses import mel_spectrogram
                    target_mel = mel_spectrogram(np.asarray(audio))
                except Exception:
                    target_mel = np.zeros((80, 10), dtype=np.float32)

                # create dummy pred mel from student_hidden for shape matching
                pred_mel = student_hidden[..., :target_mel.shape[1]].permute(0, 2, 1) if student_hidden.ndim == 3 else torch.randn((1, target_mel.shape[0], target_mel.shape[1]), device=device)
                mel_loss = mel_l1_loss(pred_mel, target_mel)

            # hard text loss: requires tokenized targets; fallback zero
            # if example contains 'input_ids' and student returned logits
            if 'input_ids' in example:
                try:
                    target_ids = torch.tensor(example['input_ids']).unsqueeze(0).to(device)
                    hard_loss = hard_text_loss(student_logits, target_ids)
                except Exception:
                    hard_loss = torch.tensor(0.0, device=device)
        except Exception:
            logging.exception("Error computing mel/hard losses; continuing with repr loss only")

        # Use SwahiliDistillationLoss for combined hard+soft loss, mix with representation & mel
        try:
            # Need labels for hard loss; if unavailable, create dummy labels (will zero CE via mask in real code)
            if 'input_ids' in example:
                labels = torch.tensor(example['input_ids']).unsqueeze(0).to(device)
            else:
                # dummy labels of shape (B, T) with zeros
                B, T, _ = student_logits.shape
                labels = torch.zeros((B, T), dtype=torch.long, device=device)

            distill_loss = crit(student_logits, teacher_logits, labels)
        except Exception:
            distill_loss = torch.tensor(0.0, device=device)

        total_loss = cfg['distillation'].get('alpha_soft', 0.5) * loss_repr + cfg['distillation'].get('alpha_mel', 1.0) * mel_loss + distill_loss

        # D. Backprop
        total_loss.backward()
        if step % cfg['training']['grad_accum'] == 0:
            optimizer.step()
            optimizer.zero_grad()

        if step % cfg['project']['log_interval'] == 0:
            logging.info(f"Step {step}: Loss = {total_loss.item():.4f}")

        if step >= 100:
            logging.info("Reached smoke-test step limit (100). Exiting.")
            break


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    run_distillation()
